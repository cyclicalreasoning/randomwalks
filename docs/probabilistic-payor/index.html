<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>Random Walks - Self-Referential Probabilistic Logic Admits the Payor's Lemma</title>
        <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <link rel="stylesheet" href="../css/default.css" />
    </head>
    <body>
        <header>
            <div class="logo">
                <a href="../">Random Walks</a>
            </div>
            <nav>
                <a href="../">Home</a>
                <a href="../about">About</a>
            </nav>
        </header>

        <main role="main">
            <h1>Self-Referential Probabilistic Logic Admits the Payor's Lemma</h1>
            <article>
    <section class="header">
        Posted on November 29, 2023
        
            by Yudhister Kumar
        
    </section>
    <section>
        <p>Better formatted version on <a href="https://www.lesswrong.com/posts/wmJT2j3rdT8ngFkPN/self-referential-probabilistic-logic-admits-the-payor-s">LessWrong</a>.</p>
<hr />
<p><em>In summary: A probabilistic version of the <a href="https://www.alignmentforum.org/posts/2WpPRrqrFQa6n2x3W/modal-fixpoint-cooperation-without-loeb-s-theorem">Payor’s Lemma</a> holds under the logic proposed in the <a href="http://intelligence.org/files/DefinabilityTruthDraft.pdf">Definability of Truth in Probabilistic Logic</a>. This gives us modal fixed-point-esque group cooperation even under probabilistic guarantees.</em></p>
<h1 id="background">Background</h1>
<p><strong>Payor’s Lemma:</strong> If <span class="math inline"> ⊢ □(□<em>x</em>→<em>x</em>) → <em>x</em>,</span> then <span class="math inline"> ⊢ <em>x</em>.</span></p>
<p>We assume two rules of inference:</p>
<ul>
<li><strong>Necessitation:</strong> <span class="math inline"> ⊢ <em>x</em> ⟹  ⊢ □<em>x</em>,</span></li>
<li><strong>Distributivity:</strong> <span class="math inline"> ⊢ □(<em>x</em>→<em>y</em>) ⟹  ⊢ □<em>x</em> → □<em>y</em>.</span></li>
</ul>
<p><strong>Proof:</strong></p>
<ol type="1">
<li><span class="math inline"> ⊢ <em>x</em> → (□<em>x</em>→<em>x</em>),</span> by tautology;</li>
<li><span class="math inline"> ⊢ □<em>x</em> → □(□<em>x</em>→<em>x</em>),</span> by 1 via necessitation and distributivity;</li>
<li><span class="math inline"> ⊢ □(□<em>x</em>→<em>x</em>) → <em>x</em></span>, by assumption;</li>
<li><span class="math inline"> ⊢ □<em>x</em> → <em>x</em>,</span> from 2 and 3 by modus ponens;</li>
<li><span class="math inline"> ⊢ □(□<em>x</em>→<em>x</em>),</span> from 4 by necessitation;</li>
<li><span class="math inline"> ⊢ <em>x</em>,</span> from 5 and 3 by modus ponens.</li>
</ol>
<p>The Payor’s Lemma is provable in all normal modal logics (as it can be proved in <span class="math inline"><em>K</em>,</span> the weakest, because it only uses necessitation and distributivity). Its proof sidesteps the assertion of an arbitrary modal fixedpoint, does not require internal necessitation (<span class="math inline"> ⊢ □<em>x</em> ⟹  ⊢ □□<em>x</em></span>), and provides the groundwork for Lobian handshake-based cooperation without Lob’s theorem.</p>
<p>It is known that Lob’s theorem <a href="https://www.lesswrong.com/posts/oBDTMnEzptBidvmw7/probabilistic-loeb-theorem">fails to hold in reflective theories of logical uncertainty</a>. However, a <a href="https://www.alignmentforum.org/posts/ZWhJcHPmRaXAPAK5k/probabilistic-payor-lemma">proof of a probabilistic Payor’s lemma</a> has been proposed, which modifies the rules of inference necessary to be:</p>
<ul>
<li><strong>Necessitation:</strong> <span class="math inline"> ⊢ <em>x</em> ⟹  ⊢ □<sub><em>p</em></sub> <em>x</em>,</span></li>
<li><strong>Weak Distributivity:</strong> <span class="math inline"> ⊢ <em>x</em> → <em>y</em> ⟹  ⊢ □<sub><em>p</em></sub> <em>x</em> → □<sub><em>p</em></sub> <em>y</em>.</span></li>
</ul>
<p>where here we take <span class="math inline">□<sub><em>p</em></sub></span> to be an operator which returns True if the internal credence of <span class="math inline"><em>x</em></span> is greater than <span class="math inline"><em>p</em></span> and False if not. (Formalisms incoming).</p>
<p>The question is then: does there exist a consistent formalism under which these rules of inference hold? The answer is yes, and it is provided by <a href="http://intelligence.org/files/DefinabilityTruthDraft.pdf">Christiano 2012</a>.
# Setup</p>
<p>(Regurgitation and rewording of the relevant parts of the <a href="http://intelligence.org/files/DefinabilityTruthDraft.pdf">Definability of Truth</a>)</p>
<p>Let <span class="math inline"><em>L</em></span> be some language and <span class="math inline"><em>T</em></span> be a theory over that language. Assume that <span class="math inline"><em>L</em></span> is powerful enough to admit a Godel encoding and that it contains terms which correspond to the rational numbers <span class="math inline">ℚ.</span> Let <span class="math inline"><em>ϕ</em><sub>1</sub>, <em>ϕ</em><sub>2</sub>…</span> be some fixed enumeration of all sentences in <span class="math inline"><em>L</em>.</span> Let <span class="math inline">⌜<em>ϕ</em>⌝</span> represent the Godel encoding of <span class="math inline"><em>ϕ</em>.</span></p>
<p>We are interested in the existence and behavior of a function <span class="math inline">ℙ : <em>L</em> → [0,1]<sup><em>L</em></sup>,</span> which assigns a real-valued probability in <span class="math inline">[0,1]</span> to each well-formed sentence of <span class="math inline"><em>L</em>.</span> We are guaranteed the coherency of <span class="math inline">ℙ</span> with the following assumptions:
1. For all <span class="math inline"><em>ϕ</em>, <em>ψ</em> ∈ <em>L</em></span> we have that <span class="math inline">ℙ(<em>ϕ</em>) = ℙ(<em>ϕ</em>∧<em>ψ</em>) + ℙ(<em>ϕ</em>∨¬<em>ψ</em>).</span>
2. For each tautology <span class="math inline"><em>ϕ</em>,</span> we have <span class="math inline">ℙ(<em>ϕ</em>) = 1.</span>
3. For each contradiction <span class="math inline"><em>ϕ</em>,</span> we have <span class="math inline">ℙ(<em>ϕ</em>) = 0.</span></p>
<p>Note: I think that 2 &amp; 3 are redundant (as says John Baez), and that these axioms do not necessarily constrain <span class="math inline">ℙ</span> to <span class="math inline">[0,1]</span> in and of themselves (hence the extra restriction). However, neither concern is relevant to the result.</p>
<p>A coherent <span class="math inline">ℙ</span> corresponds to a distribution <span class="math inline"><em>μ</em></span> over models of <span class="math inline"><em>L</em>.</span> A coherent <span class="math inline">ℙ</span> which gives probability 1 to <span class="math inline"><em>T</em></span> corresponds to a distribution <span class="math inline"><em>μ</em></span> over models of <span class="math inline"><em>T</em></span>. We denote a function which generates a distribution over models of a given theory <span class="math inline"><em>T</em></span> as <span class="math inline">ℙ<sub><em>T</em></sub>.</span></p>
<p><strong>Syntactic-Probabilistic Correspondence:</strong> Observe that <span class="math inline">ℙ<sub><em>T</em></sub>(<em>ϕ</em>) = 1 ⇔ <em>T</em> ⊢ <em>ϕ</em>.</span> This allows us to interchange the notions of syntactic consequence and probabilistic certainty.</p>
<p>Now, we want <span class="math inline">ℙ</span> to give sane probabilities to sentences which talk about the probability <span class="math inline">ℙ</span> gives them. This means that we need some way of giving <span class="math inline"><em>L</em></span> the ability to talk about itself.</p>
<p>Consider the formula <span class="math inline"><em>B</em><em>e</em><em>l</em>.</span> <span class="math inline"><em>B</em><em>e</em><em>l</em></span> takes as input the Godel encodings of sentences. <span class="math inline"><em>B</em><em>e</em><em>l</em>(⌜<em>ϕ</em>⌝)</span> contains <em>arbitrarily precise</em> information about <span class="math inline">ℙ(<em>ϕ</em>).</span> In other words, if <span class="math inline">ℙ(<em>ϕ</em>) = <em>p</em>,</span> then the statement <span class="math inline"><em>B</em><em>e</em><em>l</em>(⌜<em>ϕ</em>⌝) &gt; <em>a</em></span> is True for all <span class="math inline"><em>a</em> &lt; <em>p</em>,</span> and the statement <span class="math inline"><em>B</em><em>e</em><em>l</em>(⌜<em>ϕ</em>⌝) &gt; <em>b</em></span> is False for all <span class="math inline"><em>b</em> &gt; <em>p</em>.</span> <span class="math inline"><em>B</em><em>e</em><em>l</em></span> is fundamentally <em>a part</em> of the system, as opposed to being some metalanguage concept.</p>
<p>(These are identical properties to that represented in Christiano 2012 by <span class="math inline">ℙ(⌜<em>ϕ</em>⌝).</span> I simply choose to represent <span class="math inline">ℙ(⌜<em>ϕ</em>⌝)</span> with <span class="math inline"><em>B</em><em>e</em><em>l</em>(⌜<em>ϕ</em>⌝)</span> as it (1) reduces notational uncertainty and (2) seems to be more in the spirit of Godel’s <span class="math inline"><em>B</em><em>e</em><em>w</em></span> for provability logic).</p>
<p>Let <span class="math inline"><em>L</em>′</span> denote the language created by affixing <span class="math inline"><em>B</em><em>e</em><em>l</em></span> to <span class="math inline"><em>L</em>.</span> Then, there exists a coherent <span class="math inline">ℙ<sub><em>T</em></sub></span> for a given consistent theory <span class="math inline"><em>T</em></span> over <span class="math inline"><em>L</em></span> such that the following reflection principle is satisfied:</p>
<p><span class="math display">∀<em>ϕ</em> ∈ <em>L</em>′  ∀<em>a</em>, <em>b</em>,  ∈ ℚ : (<em>a</em>&lt;ℙ<sub><em>T</em></sub>(<em>ϕ</em>)&lt;<em>b</em>) ⟹ ℙ<sub><em>T</em></sub>(<em>a</em>&lt;<em>B</em><em>e</em><em>l</em>(⌜<em>ϕ</em>⌝)&lt;<em>b</em>) = 1.</span></p>
<p>In other words, <span class="math inline"><em>a</em> &lt; ℙ<sub><em>T</em></sub>(<em>ϕ</em>) &lt; <em>b</em></span> implies <span class="math inline"><em>T</em> ⊢ <em>a</em> &lt; <em>B</em><em>e</em><em>l</em>(⌜<em>ϕ</em>⌝) &lt; <em>b</em>.</span>
# Proof</p>
<p>(From now, for simplicity, we use <span class="math inline">ℙ</span> to refer to <span class="math inline">ℙ<sub><em>T</em></sub></span> and <span class="math inline">⊢</span> to refer to <span class="math inline"><em>T</em> ⊢ .</span> You can think of this as fixing some theory <span class="math inline"><em>T</em></span> and operating within it).</p>
<p>Let <span class="math inline">□<sub><em>p</em></sub> (<em>ϕ</em>)</span> represent the sentence <span class="math inline"><em>B</em><em>e</em><em>l</em>(⌜<em>ϕ</em>⌝) &gt; <em>p</em>,</span> for some <span class="math inline"><em>p</em> ∈ ℚ.</span> We abbreviate <span class="math inline">□<sub><em>p</em></sub> (<em>ϕ</em>)</span> as <span class="math inline">□<sub><em>p</em></sub> <em>ϕ</em>.</span> Then, we have the following:</p>
<p><strong>Probabilistic Payor’s Lemma:</strong> If <span class="math inline"> ⊢ □<sub><em>p</em></sub> (□<sub><em>p</em></sub> <em>x</em>→<em>x</em>) → <em>x</em>,</span> then <span class="math inline"> ⊢ <em>x</em>.</span></p>
<p><strong>Proof</strong> <a href="https://www.lesswrong.com/posts/ZWhJcHPmRaXAPAK5k/probabilistic-payor-lemma">as per Demski</a>:
1. <span class="math inline"> ⊢ <em>x</em> → (□<sub><em>p</em></sub> <em>x</em>→<em>x</em>),</span> by tautology;
2. <span class="math inline"> ⊢ □<sub><em>p</em></sub> <em>x</em> → □<sub><em>p</em></sub> (□<sub><em>p</em></sub> <em>x</em>→<em>x</em>),</span> by 1 via weak distributivity,
3. <span class="math inline"> ⊢ □<sub><em>p</em></sub>(□<sub><em>p</em></sub> <em>x</em>→<em>x</em>) → <em>x</em></span>, by assumption;
4. <span class="math inline"> ⊢ □<sub><em>p</em></sub> <em>x</em> → <em>x</em>,</span> from 2 and 3 by modus ponens;
5. <span class="math inline"> ⊢ □<sub><em>p</em></sub> (□<sub><em>p</em></sub> <em>x</em>→<em>x</em>),</span> from 4 by necessitation;
6. <span class="math inline"> ⊢ <em>x</em>,</span> from 5 and 3 by modus ponens.
## Rules of Inference</p>
<p><strong>Necessitation:</strong> <span class="math inline"> ⊢ <em>x</em> ⟹  ⊢ □<sub><em>p</em></sub> <em>x</em>.</span> If <span class="math inline"> ⊢ <em>x</em>,</span> then <span class="math inline">ℙ(<em>x</em>) = 1</span> by syntactic-probabilistic correspondence, so by the reflection principle we have <span class="math inline">ℙ(□<sub><em>p</em></sub> <em>x</em>) = 1,</span> and as such <span class="math inline"> ⊢ □<sub><em>p</em></sub> <em>x</em></span> by syntactic-probabilistic correspondence.</p>
<p><strong>Weak Distributivity:</strong> <span class="math inline"> ⊢ <em>x</em> → <em>y</em> ⟹  ⊢ □<sub><em>p</em></sub> <em>x</em> → □<sub><em>p</em></sub> <em>y</em>.</span> The proof of this is slightly more involved.</p>
<p>From <span class="math inline"> ⊢ <em>x</em> → <em>y</em></span> we have (via correspondence) that <span class="math inline">ℙ(<em>x</em>→<em>y</em>) = 1,</span> so <span class="math inline">ℙ(¬<em>x</em>∨<em>y</em>) = 1.</span> We want to prove that <span class="math inline">ℙ(□<sub><em>p</em></sub> <em>x</em>→□<sub><em>p</em></sub> <em>y</em>) = 1</span> from this, or <span class="math inline">ℙ((<em>B</em><em>e</em><em>l</em>(⌜<em>x</em>⌝)≤<em>p</em>)∨(<em>B</em><em>e</em><em>l</em>(⌜<em>y</em>⌝)&gt;<em>p</em>)) = 1.</span> We can do casework on <span class="math inline"><em>x</em></span>. If <span class="math inline">ℙ(<em>x</em>) ≤ <em>p</em>,</span> then weak distributivity follows from vacuousness. If <span class="math inline">ℙ(<em>x</em>) &gt; <em>p</em>,</span> then as
<span class="math display">$$
\begin{align*}
\mathbb{P}(\neg x \lor y) &amp;= \mathbb{P}(x \land(\neg x \lor y)) + \mathbb{P}(\neg x \land (\neg x \lor y)), \\
1 &amp;= \mathbb{P}(x \land y) + \mathbb{P}(\neg x \lor (\neg x \land y)), \\
1 &amp;= \mathbb{P}(x \land y) + \mathbb{P}(\neg x),
\end{align*}
$$</span>
<span class="math inline">ℙ(¬<em>x</em>) &lt; 1 − <em>p</em>,</span> so <span class="math inline">ℙ(<em>x</em>∧<em>y</em>) &lt; <em>p</em>,</span> and therefore <span class="math inline">ℙ(<em>y</em>) &gt; <em>p</em>.</span> Then, <span class="math inline"><em>B</em><em>e</em><em>l</em>(⌜<em>y</em>⌝) &gt; <em>p</em></span> is True by reflection, so by correspondence it follows that <span class="math inline"> ⊢ □<sub><em>p</em></sub> <em>x</em> → □<sub><em>p</em></sub><em>y</em>.</span></p>
<p>(I’m pretty sure this modal logic, following necessitation and weak distributivity, is not normal (it’s weaker than <span class="math inline"><em>K</em></span>). This may have some implications? But in the ‘agent’ context I don’t think that restricting ourselves to modal logics makes sense).</p>
<h1 id="bots">Bots</h1>
<p>Consider agents <span class="math inline"><em>A</em>, <em>B</em>, <em>C</em></span> which return True to signify cooperation in a multi-agent Prisoner’s Dilemma and False to signify defection. (Similar setup to <a href="https://www.alignmentforum.org/posts/2WpPRrqrFQa6n2x3W/modal-fixpoint-cooperation-without-loeb-s-theorem">Critch’s</a> ). Each agent has ‘beliefs’ <span class="math inline">ℙ<sub><em>A</em></sub>, ℙ<sub><em>B</em></sub>, ℙ<sub><em>C</em></sub> : <em>L</em> → [0,1]<sup><em>L</em></sup></span> representing their credences over all formal statements in their respective languages (we are assuming they share the same language: this is unnecessary).</p>
<p>Each agent has the ability to reason about their own ‘beliefs’ about the world arbitrarily precisely, and this allows them full knowledge of their utility function (if they are VNM agents, and up to the complexity of the world-states they can internally represent). Then, these agents can be modeled with Christiano’s probabilistic logic! And I would argue it is natural to do so (you could easily imagine an agent having access to its own beliefs with arbitrary precision by, say, repeatedly querying its own preferences).</p>
<p>Then, if <span class="math inline"><em>A</em>, <em>B</em>, <em>C</em></span> each behave in the following manner:
- <span class="math inline"> ⊢ □<sub><em>a</em></sub> (□<sub><em>e</em></sub> <em>E</em>→<em>E</em>) → <em>A</em>,</span>
- <span class="math inline"> ⊢ □<sub><em>b</em></sub> (□<sub><em>e</em></sub> <em>E</em>→<em>E</em>) → <em>B</em>,</span>
- <span class="math inline"> ⊢ □<sub><em>c</em></sub> (□<sub><em>e</em></sub> <em>E</em>→<em>E</em>) → <em>C</em>,</span></p>
<p>where <span class="math inline"><em>E</em> = <em>A</em> ∧ <em>B</em> ∧ <em>C</em></span> and <span class="math inline"><em>e</em> = max ({<em>a</em>,<em>b</em>,<em>c</em>}),</span> they will cooperate by the probabilistic Payor’s lemma.</p>
<p><strong>Proof:</strong></p>
<ol type="1">
<li><span class="math inline"> ⊢ □<sub><em>a</em></sub> (□<sub><em>e</em></sub> <em>E</em>→<em>E</em>) ∧ □<sub><em>b</em></sub> (□<sub><em>e</em></sub> <em>E</em>→<em>E</em>) ∧ □<sub><em>c</em></sub> (□<sub><em>e</em></sub> <em>E</em>→<em>E</em>) → <em>A</em> ∧ <em>B</em> ∧ <em>C</em>,</span> via conjunction;</li>
<li><span class="math inline"> ⊢ □<sub><em>e</em></sub> (□<sub><em>e</em></sub> <em>E</em>→<em>E</em>) → <em>E</em>,</span> as if the <span class="math inline"><em>e</em></span>-threshold is satisfied all others are as well;</li>
<li><span class="math inline"> ⊢ <em>E</em>,</span> by probabilistic Payor.</li>
</ol>
<p>This can be extended to arbitrarily many agents. Moreso, the valuable insight here is that cooperation is achieved <em>when the evidence that the group cooperates exceeds each and every member’s individual threshold for cooperation.</em> A formalism of the intuitive strategy ‘I will only cooperate if there are no defectors’ (or perhaps ‘we will only cooperate if there are no defectors’).</p>
<p>It is important to note that any <span class="math inline">ℙ</span> is going to be uncomputable. However, I think modeling agents as having arbitrary access to their beliefs is in line with existing ‘ideal’ models (think VNM – I suspect that this formalism closely maps to VNM agents that have access to arbitrary information about their utility function, at least in the form of preferences), and these agents play well with modal fixedpoint cooperation.</p>
<h1 id="acknowledgements">Acknowledgements</h1>
<p>This work was done while I was a 2023 Summer Research Fellow at the Center on Long-Term Risk. Many thanks to Abram Demski, my mentor who got me started on this project, as well as Sam Eisenstat for some helpful conversations. CLR was a great place to work! Would highly recommend if you’re interested in s-risk reduction.</p>
    </section>
</article>

        </main>

        <footer>
		<a href="../rss.xml">RSS</a><br>
		All thoughts my own.<br>
		Made with
		<a href="http://jaspervdj.be/hakyll">Hakyll</a>.
        </footer>
    </body>
</html>
