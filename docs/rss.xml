<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"
    xmlns:dc="http://purl.org/dc/elements/1.1/">
    <channel>
        <title>Random Walks</title>
        <link>https://ykumar.org/</link>
        <description><![CDATA[posts and musings]]></description>
        <atom:link href="https://ykumar.org//rss.xml" rel="self"
                   type="application/rss+xml" />
        <lastBuildDate>Sat, 02 Dec 2023 00:00:00 UT</lastBuildDate>
        <item>
    <title>Istanbul</title>
    <link>https://ykumar.org//istanbul</link>
    <description><![CDATA[<article>
    <section class="header">
        Posted on December  2, 2023
        
            by Yudhister Kumar
        
    </section>
    <section>
        <p><em>It’s 2AM before my flight to Istanbul. I open WizzAir’s check-in. It prompts me with my visa number. Panicked, I frantically attempt a route-around—to no avail. Resigned to confinement in the UK, I belatedly click through the Turkish e-visa application. Two minutes later, I’ve checked into my flight.</em></p>
<h1 id="vibes">vibes</h1>
<p>If God requests love, then Allah demands respect.</p>
<p>I have never experienced something quite like being (unbeknownst to others) illictly present in a mosque for <em>maghrib.</em> I pass as Muslim: I’m brown, with long black hair and a beard that implies I’m a decade older than I am. While police in front of the Blue Mosque were shouting at pale-skinned Italian tourists that non-Muslims were barred from entry, I walked straight by with nary a stray glance.</p>
<p>A church has pews; a mosque has rugs. A church has an altar; a mosque has a <em>mihrab.</em> There is no pulpit, no elevation of the imam. There is no color, no asymmetry, no idol to revere. The effigies have truly been expunged. Luther would be proud.</p>
<p>In a church, you kneel. In a mosque, you <em>bow</em>. Prostration occurs not through another (as in Communion) but through oneself. Banker, baker, beggar—all equally supplicant, deferent in the name of Allah.</p>
<p>I knew this. I did not <em>know</em> this. It’s one thing to read the Quran, another thing to practice it, and quite another thing to practice it in Istanbul in perhaps the most majestic mosque ever built.</p>
<p>The Blue Mosque is closed to non-Muslims after 7PM for prayer. I pass as Muslim, so my half-ignorant self decided to walk in (after all, it was my last day in the city). I had never felt such spiritual violation before—but I was the violator.</p>
<p>Islam demands respect in a way I haven’t seen elsewhere. Perhaps this was a consequence of intruding upon a sacred ceremony in arguably the centre of the Islamic world, and certainly the centre of the Islamic Golden Age. I don’t think so.</p>
<p>Apart from that, the food was great! Doner++</p>
<h1 id="eth-conf">eth conf</h1>
<p>DevConnect was underwhelming.</p>
<p>The coworking space was quite good. It was centrally located, near a metro station, with food provided and surrounding restaurants. Bit hard to find anyone to talk to, though. Attending the events themselves was slightly annoying, as you had to get a separate wristband for each event. The satellite events were extremely unattended, and as always, advice for conferences like these is to find friends and/or come with friends.</p>
<p>Progcrypto was overwhelming! 0xparc put on a wonderful event, with accessible workshops, great talks, and even better palate cleansers. Met the Axiom lead and Wei Dai (not that Wei Dai).</p>
<h1 id="maths-communes">maths communes</h1>
<p><a href="https://nesinkoyleri.org/">Nesin Kolyeri</a> is one of a kind. A village in the Anatolian hills dedicated to educating the next generation about the wonders of mathematics. Founded by a prominent Erdogan critic, Ali Nesin, it is run by the people for the people (with a very tasteful library).</p>
<p>0xVillage was an event hosted by the village to bring together researchers working on the cutting edge of cryptographic methods—I went, and had a blast. Learned what fully holomorphic encryption was, how to write ZK circuits in Rust, and figured out that the crypto community had a different ArXiV (e-print).
loved &lt;3</p>
    </section>
</article>
]]></description>
    <pubDate>Sat, 02 Dec 2023 00:00:00 UT</pubDate>
    <guid>https://ykumar.org//istanbul</guid>
    <dc:creator>Yudhister Kumar</dc:creator>
</item>
<item>
    <title>Self-Referential Probabilistic Logic Admits the Payor's Lemma</title>
    <link>https://ykumar.org//probabilistic-payor</link>
    <description><![CDATA[<article>
    <section class="header">
        Posted on November 29, 2023
        
            by Yudhister Kumar
        
    </section>
    <section>
        <p>Better formatted version on <a href="https://www.lesswrong.com/posts/wmJT2j3rdT8ngFkPN/self-referential-probabilistic-logic-admits-the-payor-s">LessWrong</a>.</p>
<hr />
<p><em>In summary: A probabilistic version of the <a href="https://www.alignmentforum.org/posts/2WpPRrqrFQa6n2x3W/modal-fixpoint-cooperation-without-loeb-s-theorem">Payor’s Lemma</a> holds under the logic proposed in the <a href="http://intelligence.org/files/DefinabilityTruthDraft.pdf">Definability of Truth in Probabilistic Logic</a>. This gives us modal fixed-point-esque group cooperation even under probabilistic guarantees.</em></p>
<h1 id="background">Background</h1>
<p><strong>Payor’s Lemma:</strong> If <span class="math inline"> ⊢ □(□<em>x</em>→<em>x</em>) → <em>x</em>,</span> then <span class="math inline"> ⊢ <em>x</em>.</span></p>
<p>We assume two rules of inference:</p>
<ul>
<li><strong>Necessitation:</strong> <span class="math inline"> ⊢ <em>x</em> ⟹  ⊢ □<em>x</em>,</span></li>
<li><strong>Distributivity:</strong> <span class="math inline"> ⊢ □(<em>x</em>→<em>y</em>) ⟹  ⊢ □<em>x</em> → □<em>y</em>.</span></li>
</ul>
<p><strong>Proof:</strong></p>
<ol type="1">
<li><span class="math inline"> ⊢ <em>x</em> → (□<em>x</em>→<em>x</em>),</span> by tautology;</li>
<li><span class="math inline"> ⊢ □<em>x</em> → □(□<em>x</em>→<em>x</em>),</span> by 1 via necessitation and distributivity;</li>
<li><span class="math inline"> ⊢ □(□<em>x</em>→<em>x</em>) → <em>x</em></span>, by assumption;</li>
<li><span class="math inline"> ⊢ □<em>x</em> → <em>x</em>,</span> from 2 and 3 by modus ponens;</li>
<li><span class="math inline"> ⊢ □(□<em>x</em>→<em>x</em>),</span> from 4 by necessitation;</li>
<li><span class="math inline"> ⊢ <em>x</em>,</span> from 5 and 3 by modus ponens.</li>
</ol>
<p>The Payor’s Lemma is provable in all normal modal logics (as it can be proved in <span class="math inline"><em>K</em>,</span> the weakest, because it only uses necessitation and distributivity). Its proof sidesteps the assertion of an arbitrary modal fixedpoint, does not require internal necessitation (<span class="math inline"> ⊢ □<em>x</em> ⟹  ⊢ □□<em>x</em></span>), and provides the groundwork for Lobian handshake-based cooperation without Lob’s theorem.</p>
<p>It is known that Lob’s theorem <a href="https://www.lesswrong.com/posts/oBDTMnEzptBidvmw7/probabilistic-loeb-theorem">fails to hold in reflective theories of logical uncertainty</a>. However, a <a href="https://www.alignmentforum.org/posts/ZWhJcHPmRaXAPAK5k/probabilistic-payor-lemma">proof of a probabilistic Payor’s lemma</a> has been proposed, which modifies the rules of inference necessary to be:</p>
<ul>
<li><strong>Necessitation:</strong> <span class="math inline"> ⊢ <em>x</em> ⟹  ⊢ □<sub><em>p</em></sub> <em>x</em>,</span></li>
<li><strong>Weak Distributivity:</strong> <span class="math inline"> ⊢ <em>x</em> → <em>y</em> ⟹  ⊢ □<sub><em>p</em></sub> <em>x</em> → □<sub><em>p</em></sub> <em>y</em>.</span></li>
</ul>
<p>where here we take <span class="math inline">□<sub><em>p</em></sub></span> to be an operator which returns True if the internal credence of <span class="math inline"><em>x</em></span> is greater than <span class="math inline"><em>p</em></span> and False if not. (Formalisms incoming).</p>
<p>The question is then: does there exist a consistent formalism under which these rules of inference hold? The answer is yes, and it is provided by <a href="http://intelligence.org/files/DefinabilityTruthDraft.pdf">Christiano 2012</a>.
# Setup</p>
<p>(Regurgitation and rewording of the relevant parts of the <a href="http://intelligence.org/files/DefinabilityTruthDraft.pdf">Definability of Truth</a>)</p>
<p>Let <span class="math inline"><em>L</em></span> be some language and <span class="math inline"><em>T</em></span> be a theory over that language. Assume that <span class="math inline"><em>L</em></span> is powerful enough to admit a Godel encoding and that it contains terms which correspond to the rational numbers <span class="math inline">ℚ.</span> Let <span class="math inline"><em>ϕ</em><sub>1</sub>, <em>ϕ</em><sub>2</sub>…</span> be some fixed enumeration of all sentences in <span class="math inline"><em>L</em>.</span> Let <span class="math inline">⌜<em>ϕ</em>⌝</span> represent the Godel encoding of <span class="math inline"><em>ϕ</em>.</span></p>
<p>We are interested in the existence and behavior of a function <span class="math inline">ℙ : <em>L</em> → [0,1]<sup><em>L</em></sup>,</span> which assigns a real-valued probability in <span class="math inline">[0,1]</span> to each well-formed sentence of <span class="math inline"><em>L</em>.</span> We are guaranteed the coherency of <span class="math inline">ℙ</span> with the following assumptions:
1. For all <span class="math inline"><em>ϕ</em>, <em>ψ</em> ∈ <em>L</em></span> we have that <span class="math inline">ℙ(<em>ϕ</em>) = ℙ(<em>ϕ</em>∧<em>ψ</em>) + ℙ(<em>ϕ</em>∨¬<em>ψ</em>).</span>
2. For each tautology <span class="math inline"><em>ϕ</em>,</span> we have <span class="math inline">ℙ(<em>ϕ</em>) = 1.</span>
3. For each contradiction <span class="math inline"><em>ϕ</em>,</span> we have <span class="math inline">ℙ(<em>ϕ</em>) = 0.</span></p>
<p>Note: I think that 2 &amp; 3 are redundant (as says John Baez), and that these axioms do not necessarily constrain <span class="math inline">ℙ</span> to <span class="math inline">[0,1]</span> in and of themselves (hence the extra restriction). However, neither concern is relevant to the result.</p>
<p>A coherent <span class="math inline">ℙ</span> corresponds to a distribution <span class="math inline"><em>μ</em></span> over models of <span class="math inline"><em>L</em>.</span> A coherent <span class="math inline">ℙ</span> which gives probability 1 to <span class="math inline"><em>T</em></span> corresponds to a distribution <span class="math inline"><em>μ</em></span> over models of <span class="math inline"><em>T</em></span>. We denote a function which generates a distribution over models of a given theory <span class="math inline"><em>T</em></span> as <span class="math inline">ℙ<sub><em>T</em></sub>.</span></p>
<p><strong>Syntactic-Probabilistic Correspondence:</strong> Observe that <span class="math inline">ℙ<sub><em>T</em></sub>(<em>ϕ</em>) = 1 ⇔ <em>T</em> ⊢ <em>ϕ</em>.</span> This allows us to interchange the notions of syntactic consequence and probabilistic certainty.</p>
<p>Now, we want <span class="math inline">ℙ</span> to give sane probabilities to sentences which talk about the probability <span class="math inline">ℙ</span> gives them. This means that we need some way of giving <span class="math inline"><em>L</em></span> the ability to talk about itself.</p>
<p>Consider the formula <span class="math inline"><em>B</em><em>e</em><em>l</em>.</span> <span class="math inline"><em>B</em><em>e</em><em>l</em></span> takes as input the Godel encodings of sentences. <span class="math inline"><em>B</em><em>e</em><em>l</em>(⌜<em>ϕ</em>⌝)</span> contains <em>arbitrarily precise</em> information about <span class="math inline">ℙ(<em>ϕ</em>).</span> In other words, if <span class="math inline">ℙ(<em>ϕ</em>) = <em>p</em>,</span> then the statement <span class="math inline"><em>B</em><em>e</em><em>l</em>(⌜<em>ϕ</em>⌝) &gt; <em>a</em></span> is True for all <span class="math inline"><em>a</em> &lt; <em>p</em>,</span> and the statement <span class="math inline"><em>B</em><em>e</em><em>l</em>(⌜<em>ϕ</em>⌝) &gt; <em>b</em></span> is False for all <span class="math inline"><em>b</em> &gt; <em>p</em>.</span> <span class="math inline"><em>B</em><em>e</em><em>l</em></span> is fundamentally <em>a part</em> of the system, as opposed to being some metalanguage concept.</p>
<p>(These are identical properties to that represented in Christiano 2012 by <span class="math inline">ℙ(⌜<em>ϕ</em>⌝).</span> I simply choose to represent <span class="math inline">ℙ(⌜<em>ϕ</em>⌝)</span> with <span class="math inline"><em>B</em><em>e</em><em>l</em>(⌜<em>ϕ</em>⌝)</span> as it (1) reduces notational uncertainty and (2) seems to be more in the spirit of Godel’s <span class="math inline"><em>B</em><em>e</em><em>w</em></span> for provability logic).</p>
<p>Let <span class="math inline"><em>L</em>′</span> denote the language created by affixing <span class="math inline"><em>B</em><em>e</em><em>l</em></span> to <span class="math inline"><em>L</em>.</span> Then, there exists a coherent <span class="math inline">ℙ<sub><em>T</em></sub></span> for a given consistent theory <span class="math inline"><em>T</em></span> over <span class="math inline"><em>L</em></span> such that the following reflection principle is satisfied:</p>
<p><span class="math display">∀<em>ϕ</em> ∈ <em>L</em>′  ∀<em>a</em>, <em>b</em>,  ∈ ℚ : (<em>a</em>&lt;ℙ<sub><em>T</em></sub>(<em>ϕ</em>)&lt;<em>b</em>) ⟹ ℙ<sub><em>T</em></sub>(<em>a</em>&lt;<em>B</em><em>e</em><em>l</em>(⌜<em>ϕ</em>⌝)&lt;<em>b</em>) = 1.</span></p>
<p>In other words, <span class="math inline"><em>a</em> &lt; ℙ<sub><em>T</em></sub>(<em>ϕ</em>) &lt; <em>b</em></span> implies <span class="math inline"><em>T</em> ⊢ <em>a</em> &lt; <em>B</em><em>e</em><em>l</em>(⌜<em>ϕ</em>⌝) &lt; <em>b</em>.</span>
# Proof</p>
<p>(From now, for simplicity, we use <span class="math inline">ℙ</span> to refer to <span class="math inline">ℙ<sub><em>T</em></sub></span> and <span class="math inline">⊢</span> to refer to <span class="math inline"><em>T</em> ⊢ .</span> You can think of this as fixing some theory <span class="math inline"><em>T</em></span> and operating within it).</p>
<p>Let <span class="math inline">□<sub><em>p</em></sub> (<em>ϕ</em>)</span> represent the sentence <span class="math inline"><em>B</em><em>e</em><em>l</em>(⌜<em>ϕ</em>⌝) &gt; <em>p</em>,</span> for some <span class="math inline"><em>p</em> ∈ ℚ.</span> We abbreviate <span class="math inline">□<sub><em>p</em></sub> (<em>ϕ</em>)</span> as <span class="math inline">□<sub><em>p</em></sub> <em>ϕ</em>.</span> Then, we have the following:</p>
<p><strong>Probabilistic Payor’s Lemma:</strong> If <span class="math inline"> ⊢ □<sub><em>p</em></sub> (□<sub><em>p</em></sub> <em>x</em>→<em>x</em>) → <em>x</em>,</span> then <span class="math inline"> ⊢ <em>x</em>.</span></p>
<p><strong>Proof</strong> <a href="https://www.lesswrong.com/posts/ZWhJcHPmRaXAPAK5k/probabilistic-payor-lemma">as per Demski</a>:
1. <span class="math inline"> ⊢ <em>x</em> → (□<sub><em>p</em></sub> <em>x</em>→<em>x</em>),</span> by tautology;
2. <span class="math inline"> ⊢ □<sub><em>p</em></sub> <em>x</em> → □<sub><em>p</em></sub> (□<sub><em>p</em></sub> <em>x</em>→<em>x</em>),</span> by 1 via weak distributivity,
3. <span class="math inline"> ⊢ □<sub><em>p</em></sub>(□<sub><em>p</em></sub> <em>x</em>→<em>x</em>) → <em>x</em></span>, by assumption;
4. <span class="math inline"> ⊢ □<sub><em>p</em></sub> <em>x</em> → <em>x</em>,</span> from 2 and 3 by modus ponens;
5. <span class="math inline"> ⊢ □<sub><em>p</em></sub> (□<sub><em>p</em></sub> <em>x</em>→<em>x</em>),</span> from 4 by necessitation;
6. <span class="math inline"> ⊢ <em>x</em>,</span> from 5 and 3 by modus ponens.
## Rules of Inference</p>
<p><strong>Necessitation:</strong> <span class="math inline"> ⊢ <em>x</em> ⟹  ⊢ □<sub><em>p</em></sub> <em>x</em>.</span> If <span class="math inline"> ⊢ <em>x</em>,</span> then <span class="math inline">ℙ(<em>x</em>) = 1</span> by syntactic-probabilistic correspondence, so by the reflection principle we have <span class="math inline">ℙ(□<sub><em>p</em></sub> <em>x</em>) = 1,</span> and as such <span class="math inline"> ⊢ □<sub><em>p</em></sub> <em>x</em></span> by syntactic-probabilistic correspondence.</p>
<p><strong>Weak Distributivity:</strong> <span class="math inline"> ⊢ <em>x</em> → <em>y</em> ⟹  ⊢ □<sub><em>p</em></sub> <em>x</em> → □<sub><em>p</em></sub> <em>y</em>.</span> The proof of this is slightly more involved.</p>
<p>From <span class="math inline"> ⊢ <em>x</em> → <em>y</em></span> we have (via correspondence) that <span class="math inline">ℙ(<em>x</em>→<em>y</em>) = 1,</span> so <span class="math inline">ℙ(¬<em>x</em>∨<em>y</em>) = 1.</span> We want to prove that <span class="math inline">ℙ(□<sub><em>p</em></sub> <em>x</em>→□<sub><em>p</em></sub> <em>y</em>) = 1</span> from this, or <span class="math inline">ℙ((<em>B</em><em>e</em><em>l</em>(⌜<em>x</em>⌝)≤<em>p</em>)∨(<em>B</em><em>e</em><em>l</em>(⌜<em>y</em>⌝)&gt;<em>p</em>)) = 1.</span> We can do casework on <span class="math inline"><em>x</em></span>. If <span class="math inline">ℙ(<em>x</em>) ≤ <em>p</em>,</span> then weak distributivity follows from vacuousness. If <span class="math inline">ℙ(<em>x</em>) &gt; <em>p</em>,</span> then as
<span class="math display">$$
\begin{align*}
\mathbb{P}(\neg x \lor y) &amp;= \mathbb{P}(x \land(\neg x \lor y)) + \mathbb{P}(\neg x \land (\neg x \lor y)), \\
1 &amp;= \mathbb{P}(x \land y) + \mathbb{P}(\neg x \lor (\neg x \land y)), \\
1 &amp;= \mathbb{P}(x \land y) + \mathbb{P}(\neg x),
\end{align*}
$$</span>
<span class="math inline">ℙ(¬<em>x</em>) &lt; 1 − <em>p</em>,</span> so <span class="math inline">ℙ(<em>x</em>∧<em>y</em>) &lt; <em>p</em>,</span> and therefore <span class="math inline">ℙ(<em>y</em>) &gt; <em>p</em>.</span> Then, <span class="math inline"><em>B</em><em>e</em><em>l</em>(⌜<em>y</em>⌝) &gt; <em>p</em></span> is True by reflection, so by correspondence it follows that <span class="math inline"> ⊢ □<sub><em>p</em></sub> <em>x</em> → □<sub><em>p</em></sub><em>y</em>.</span></p>
<p>(I’m pretty sure this modal logic, following necessitation and weak distributivity, is not normal (it’s weaker than <span class="math inline"><em>K</em></span>). This may have some implications? But in the ‘agent’ context I don’t think that restricting ourselves to modal logics makes sense).</p>
<h1 id="bots">Bots</h1>
<p>Consider agents <span class="math inline"><em>A</em>, <em>B</em>, <em>C</em></span> which return True to signify cooperation in a multi-agent Prisoner’s Dilemma and False to signify defection. (Similar setup to <a href="https://www.alignmentforum.org/posts/2WpPRrqrFQa6n2x3W/modal-fixpoint-cooperation-without-loeb-s-theorem">Critch’s</a> ). Each agent has ‘beliefs’ <span class="math inline">ℙ<sub><em>A</em></sub>, ℙ<sub><em>B</em></sub>, ℙ<sub><em>C</em></sub> : <em>L</em> → [0,1]<sup><em>L</em></sup></span> representing their credences over all formal statements in their respective languages (we are assuming they share the same language: this is unnecessary).</p>
<p>Each agent has the ability to reason about their own ‘beliefs’ about the world arbitrarily precisely, and this allows them full knowledge of their utility function (if they are VNM agents, and up to the complexity of the world-states they can internally represent). Then, these agents can be modeled with Christiano’s probabilistic logic! And I would argue it is natural to do so (you could easily imagine an agent having access to its own beliefs with arbitrary precision by, say, repeatedly querying its own preferences).</p>
<p>Then, if <span class="math inline"><em>A</em>, <em>B</em>, <em>C</em></span> each behave in the following manner:
- <span class="math inline"> ⊢ □<sub><em>a</em></sub> (□<sub><em>e</em></sub> <em>E</em>→<em>E</em>) → <em>A</em>,</span>
- <span class="math inline"> ⊢ □<sub><em>b</em></sub> (□<sub><em>e</em></sub> <em>E</em>→<em>E</em>) → <em>B</em>,</span>
- <span class="math inline"> ⊢ □<sub><em>c</em></sub> (□<sub><em>e</em></sub> <em>E</em>→<em>E</em>) → <em>C</em>,</span></p>
<p>where <span class="math inline"><em>E</em> = <em>A</em> ∧ <em>B</em> ∧ <em>C</em></span> and <span class="math inline"><em>e</em> = max ({<em>a</em>,<em>b</em>,<em>c</em>}),</span> they will cooperate by the probabilistic Payor’s lemma.</p>
<p><strong>Proof:</strong></p>
<ol type="1">
<li><span class="math inline"> ⊢ □<sub><em>a</em></sub> (□<sub><em>e</em></sub> <em>E</em>→<em>E</em>) ∧ □<sub><em>b</em></sub> (□<sub><em>e</em></sub> <em>E</em>→<em>E</em>) ∧ □<sub><em>c</em></sub> (□<sub><em>e</em></sub> <em>E</em>→<em>E</em>) → <em>A</em> ∧ <em>B</em> ∧ <em>C</em>,</span> via conjunction;</li>
<li><span class="math inline"> ⊢ □<sub><em>e</em></sub> (□<sub><em>e</em></sub> <em>E</em>→<em>E</em>) → <em>E</em>,</span> as if the <span class="math inline"><em>e</em></span>-threshold is satisfied all others are as well;</li>
<li><span class="math inline"> ⊢ <em>E</em>,</span> by probabilistic Payor.</li>
</ol>
<p>This can be extended to arbitrarily many agents. Moreso, the valuable insight here is that cooperation is achieved <em>when the evidence that the group cooperates exceeds each and every member’s individual threshold for cooperation.</em> A formalism of the intuitive strategy ‘I will only cooperate if there are no defectors’ (or perhaps ‘we will only cooperate if there are no defectors’).</p>
<p>It is important to note that any <span class="math inline">ℙ</span> is going to be uncomputable. However, I think modeling agents as having arbitrary access to their beliefs is in line with existing ‘ideal’ models (think VNM – I suspect that this formalism closely maps to VNM agents that have access to arbitrary information about their utility function, at least in the form of preferences), and these agents play well with modal fixedpoint cooperation.</p>
<h1 id="acknowledgements">Acknowledgements</h1>
<p>This work was done while I was a 2023 Summer Research Fellow at the Center on Long-Term Risk. Many thanks to Abram Demski, my mentor who got me started on this project, as well as Sam Eisenstat for some helpful conversations. CLR was a great place to work! Would highly recommend if you’re interested in s-risk reduction.</p>
    </section>
</article>
]]></description>
    <pubDate>Wed, 29 Nov 2023 00:00:00 UT</pubDate>
    <guid>https://ykumar.org//probabilistic-payor</guid>
    <dc:creator>Yudhister Kumar</dc:creator>
</item>
<item>
    <title>Ideas</title>
    <link>https://ykumar.org//ideas</link>
    <description><![CDATA[<article>
    <section class="header">
        Posted on November  3, 2023
        
            by Yudhister Kumar
        
    </section>
    <section>
        <p><em>half-baked ideas. you know the drill.</em></p>
<hr />
<h1 id="feynman-diagrams-gnns">Feynman Diagrams &amp; GNNs</h1>
<p>This one has been on my mind for a while (March 2022).</p>
<p>Fundamentally, Feynman diagrams are just graphs. So, you could probably fit a GNN to a dataset of existing Feynman diagrams and have it learn heuristics to compute them better.</p>
<p><a href="https://arxiv.org/pdf/2211.15348.pdf">Turns out this was done in Nov 2022</a>. Abstract:</p>
<blockquote>
<p>In the wake of the growing popularity of machine learning in particle physics, this
work finds a new application of geometric deep learning on Feynman diagrams to
make accurate and fast matrix element predictions with the potential to be used
in analysis of quantum field theory. This research uses the graph attention layer
which makes matrix element predictions to 1 significant figure accuracy above 90%
of the time. Peak performance was achieved in making predictions to 3 significant
figure accuracy over 10% of the time with less than 200 epochs of training, serving
as a proof of concept on which future works can build upon for better performance.
Finally, a procedure is suggested, to use the network to make advancements in
quantum field theory by constructing Feynman diagrams with effective particles
that represent non-perturbative calculations.</p>
</blockquote>
<p>But there’s more work to do – this is a proof of concept only tested on a limited dataset. I’m excited about integrating this with symbolic regression to recover potentially closed-form heuristics, or applying this to stuff like QCD where Feynman diagram computation is intractable (?)</p>
<p>(although my knowledge of fundamental physics is very lacking)</p>
<h2 id="gnn-stuff">GNN Stuff</h2>
<ul>
<li><a href="https://pytorch-geometric.readthedocs.io/en/latest/">Pytorch Geometric</a></li>
<li><a href="https://github.com/google-deepmind/jraph">Jraph</a> – DeepMind’s JAX based GNN software. Has a really cool <a href="https://github.com/google-deepmind/jraph/blob/master/jraph/examples/higgs_detection.py">Higgs boson detection algorithm</a> as an example. I find this more intuitive than PyG, but also maybe not maintained as well? although it’s been a solid year since I looked at it</li>
<li>I don’t think there’s that much other stuff I’m missing. Maybe good resources for understanding how GNNs work.</li>
</ul>
<h2 id="feynman-diagram-stuff">Feynman Diagram Stuff</h2>
<p>(stuff that might be useful for understanding how to represent Feynman diagrams as graphs idk)</p>
<ul>
<li><a href="https://arxiv.org/pdf/math/0106001.pdf">Feymman Diagrams Via Graphical Calculus</a></li>
<li><a href="https://arxiv.org/pdf/1602.04182.pdf">Feynman Diagrams for Beginners</a></li>
<li>a bunch of other stuff I’m missing</li>
</ul>
<h2 id="symbolic-regression">Symbolic Regression</h2>
<ul>
<li><a href="https://astroautomata.com/PySR/">PySR</a> by Miles Crammer is the only decent symbolic regression software that exists nowdays. The documentation is on his website, not on PyPI. Beware.</li>
<li><a href="https://arxiv.org/pdf/2006.11287.pdf">Discovering Symbolic Models from Deep Learning with Inductive Biases</a> Miles Crammer et. al. use PySR &amp; GNNs to recover &amp; create astrophysics formulae, as well as recovering Newtonian &amp; Hamiltonian dynamics</li>
<li>a bunch of other papers I’m missing</li>
</ul>
<h2 id="bottlenecks">Bottlenecks</h2>
<p>How to represent Feynman diagrams as graphs? Mitchell et. al. have a good formulation which I should still understand better. So, concrete steps:</p>
<ul>
<li>replicate Mitchell et. al. 2022</li>
<li>figure out how it’s limited (likely can’t consider loop diagrams)</li>
<li>CERN is beginning to adopt novel algos for churning through the hundreds of terabytes of data they create each day. They have some really cool stuff on classifying particle jets, and some really cool datasets. Make a better algorithm for that</li>
<li>profit?</li>
</ul>
<h1 id="half-baked">Half-Baked</h1>
<ul>
<li>Longtermism is fake because any practical value model needs to have a time discount factor (for practicality)</li>
<li></li>
</ul>
    </section>
</article>
]]></description>
    <pubDate>Fri, 03 Nov 2023 00:00:00 UT</pubDate>
    <guid>https://ykumar.org//ideas</guid>
    <dc:creator>Yudhister Kumar</dc:creator>
</item>
<item>
    <title>Chip War</title>
    <link>https://ykumar.org//chip-war</link>
    <description><![CDATA[<article>
    <section class="header">
        Posted on October 29, 2023
        
            by Yudhister Kumar
        
    </section>
    <section>
        <p><img src="/images/chip-war.jpg" style="float: right; margin: 16px;" width=250 /></p>
<h1 id="rating-35">Rating: 3/5</h1>
<p>A gripping thriller from the subject matter, not the prose. The workhorses of the digital age do not disappoint.</p>
<blockquote>
TSMC replicated this process at a scale previously unparalleled in human history. Apple sold over 100 million iPhone 12s, each powered by an A14 processor chip with 11.8 billion tiny transistors carved into its silicon. In a matter of months, in other words, for just one of the dozen chips in an iPhone, TSMC’s Fab 18 fabricated well over <b>1 quintillion transistors</b> – that is, a number with eighteen zeros behind it. Last year, the chip industry produced more transistors than the combined quantities of all goods produced by all other companies, in all other industries, in all human history. Nothing else comes close.
</blockquote>
<p>The Japanese asset bubble was in large part due to their burgeoning chip industry. Unlike the Soviets (copycats barred from American markets), the Japanese were copycats with access to American markets – Uncle Sam wanted a democratic, capitalistic counterweight in the Far East to the USSR and Communist China. 1946: Sony was founded; 1953: Sony began manufacturing transistors; 1964: Japan produced more transistors than the US.</p>
<blockquote>
Sony excelled by identifying new markets and targeting them with impressive products using Silicon Valley’s newest circuitry technology. “Our plan is to lead the public with new products rather than ask them what products they want,” Morita declared. “The public does not know what is possible, but we do.”
</blockquote>
<p>Sony’s dominance of the electronics market didn’t come into full effect until the 1970s, when Texas Instruments missed its opportunities with handheld consumer markets. But even before this, both countries began to engage in protectionist policies – chip firms began to lobby against offshoring production, and Japan pumped money into its consumer electronics market (and then it crashed :P).</p>
<blockquote>
In the early 1960s, it had been possible to claim the Pentagon had created Silicon Valley. IN the decade since, the tables had turned. The U.S. military lost the war in Vietnam, but the chip industry won the peace that followed, binding the rest of Asia, from Singapore to Taiwan to Japan, more closely to the U.S. via rapidly expanding investment links and supply chains. The entire world was more tightly connected to America’s innovation infrastructure, and even adversaries like the USSR spent their time copying U.S. chips and chipmaking tools. Meanwhile, the chip industry had catalyzed an array of new weapons systems that were remaking how the U.S. military would fight future wars. American power was being recast. Now the entire valley dependent on Silicon Valley’s success.
</blockquote>
<p>We know the story from here: Silicon Valley began desigining, rather than manufacturing chips; chip production got offshored to Asia, notably to Morris Chang’s TSMC in Taiwan; Intel rose from Fairchild’s founding team to become the dominant chip designer and the only American chip manufacturer.</p>
<p>I want to jump to 1992, when Intel started dumping R&amp;D funding into EUV. EUV (extreme ultraviolet) machines are the reason why TSMC is able to make sub 7nm nodes, and they’ve been in development for well over thirty years. The only manufacturer of EUV lithography in the world is the Dutch company ASML. The same ASML that Intel’s been funding for nearly thirty years to produce EUV tech.</p>
<p>Without ASML, TSMC can’t produce NVIDIA’s new GPUs. While it is true that TSMC’s fabs are the only chip fabs currently at the frontier, it is important to notice that they are not the only chokepoint for chip production (relevant for compute governance). Notably, the Netherlands are more beholden to the EU than the USA. To produce better and better chips, the world needs access to better and better lithography manufactures. These manufacturers are located in neither the US nor Taiwan. Perhaps targeting these with regulation is viable.</p>
<p>Intel is dead now, especially after they turned down the chance to manufacture mobile chips. Even recently, AMD beat them at their consumer hardware CPU game, and they’re desperately playing catchup with their new GPU and CPU lines. The bread and butter of chip innovation now happens offshore – in Taiwan, the Netherlands, or elsewhere – and America should be wary.</p>
<p>(It will still take China years to catch up. But good chips are in the West, not the US, and this is good to keep in mind).</p>
    </section>
</article>
]]></description>
    <pubDate>Sun, 29 Oct 2023 00:00:00 UT</pubDate>
    <guid>https://ykumar.org//chip-war</guid>
    <dc:creator>Yudhister Kumar</dc:creator>
</item>
<item>
    <title>Butler to the World</title>
    <link>https://ykumar.org//butler-to-the-world</link>
    <description><![CDATA[<article>
    <section class="header">
        Posted on October 29, 2023
        
            by Yudhister Kumar
        
    </section>
    <section>
        <p><img src="/images/butler-to-the-world.jpg" style="float: right; margin: 16px;" width=250 /></p>
<h1 id="rating-45">Rating: 4/5</h1>
<p>Bullough is, if nothing else, a great storyteller. His story of the British financial underworld focuses less on its sheer magnitude (4000 GBP in fraudulent money passes through the UK for each person in it) and more on its hidden quirks (private prosecutions are Butler Britain’s correction mechanism), but it’s very entertaining. It paints a picture for you that, if accurate, is telling.</p>
<p>Scottish Limited Partnerships, shell companies in the British Virgin Islands, Gibraltar’s gaming industry (soon to be crypto), London’s sheltering of Russian-backed Ukrainian energy tycoons, and the use of private prosecutions as Butler Britain’s corrective mechanism all have their time in the limelight. For each, the same story: lax British policies let criminals hide in plain sight.</p>
<p>The author’s contempt for the ‘men of the City’ pierces through, but this does not detract immensely from his analysis. Rather, it opens the door for funny quips targeted at the British pseudo-aristocracy. He opens with a mention of his brief stint at a butlering school and switfly being kicked out. This landed, while others fall somewhat flat (a mention of his poor interview with Parliament &amp; his uncombed hair and not-fitted suit).</p>
<p>(Apparently those who ran the Bank of England in the 1960s didn’t even attend universities! They were just Eton boys, ‘public schoolboys’, who controlled the levers of financial power and paved the way for lax restrictions on financial practice on this side of the Atlantic.)</p>
<p>This book is neither meant to give policy prescriptions nor shower the reader with facts and figures of British financial crime. It’s a good story, a well-researched one at that.</p>
    </section>
</article>
]]></description>
    <pubDate>Sun, 29 Oct 2023 00:00:00 UT</pubDate>
    <guid>https://ykumar.org//butler-to-the-world</guid>
    <dc:creator>Yudhister Kumar</dc:creator>
</item>
<item>
    <title>Aesthetics</title>
    <link>https://ykumar.org//aesthetics</link>
    <description><![CDATA[<article>
    <section class="header">
        Posted on October 14, 2023
        
            by Yudhister Kumar
        
    </section>
    <section>
        <p><em>I had some scrawled handwritten notes I thought were vaguely interesting and a Rambles section on my site. See below.</em></p>
<hr />
<p><u>Thought:</u> motivate aesthetics with disgust.</p>
<p>Consider aesthetics as applied physiology (ala Nietzsche). We are either healthy or we are not. Health is the natural, the good state of being. Under this framing it makes more sense to consider pathogenic and unnatural influences rather than nominally ‘good’ ones (which are simply neutral).</p>
<p><u>Thought:</u> there exists a naturalistic basis for ‘beauty’.</p>
<ul>
<li>The Harmonic Series</li>
<li>Visual beauty is the ~same across bees/birds/humans</li>
<li>good smells are good across organisms??</li>
</ul>
<p>The simplicity bias &amp; the <a href="https://people.idsia.ch/~juergen/beauty.html">complexity-based theory of beauty</a></p>
<p><u>Thought:</u> physiological aesthetes are grounded in disgust, while cognitive aesthetes are grounded in beauty</p>
<p>(‘disgust’ and ‘beauty’ are the wrong words to describe this dichotomy)</p>
<p>Similar to Mill’s higher and lower pleasures: cognitive aesthetes &gt; physiological aesthetes. But cognitive aesthetes can have both positive and negative valence, while physiological is only negative? Perhaps cognitive aesthetes can only be positive valence, and the negativity arises from a physiological reaction?</p>
<p>System 1 v. System 2, push v. pull factors</p>
<p>Sex is physiological and a pull factor! =&gt; wrong to say that physiological aesthetes are always negative valence. Also consider food, music</p>
<p><u>Thought:</u> pull aesthetes need to be (<em>something? I can’t read my own handwriting</em>)</p>
<p>E.g. music –</p>
<ul>
<li><a href="https://open.spotify.com/track/2rn0s6hslbgBoKBFgoaKH5?si=cda783e0281c44b5">Mahler X</a> vs. <a href="https://open.spotify.com/track/29y2j3s6i528lBTSMP0wbE?si=de1ffce2aa424fae">Sabaton’s 1916</a></li>
</ul>
<p>greatness is at the intersection of phys &amp; cognitive aesthetes: e.g. Beethoven</p>
<p>No <del>good</del> great contemporary classical because tipped too far in cognitive direction</p>
<p>same with art</p>
<p><u>Thought:</u> Can you get DALLE-3 (or the music equivalent) to innovate here?</p>
<p><u>Thought:</u> What about context:</p>
<p>Physiological context window:</p>
<ul>
<li>Amount of melodies</li>
<li>Amount of harmonic simplicity (well-approximation by rational pitch ratios)</li>
<li>volume</li>
</ul>
<p>Cognitive context window:</p>
<ul>
<li>Complexity of lyrics</li>
<li>how many thiings you’re tracking?</li>
</ul>
<p>Great music that expands your cognitive capacity – ?</p>
<p>Ravel’s <em>Le Tombeau de Couperin, II. Fugue</em> has a 4-note motif with ~no rhythmic variation and yet elicits complexity on a baser &amp; higher level</p>
<hr />
<p>Quite unsure of what I was trying to do here.</p>
<p>The “aesthetics as applied physiology” frame comes from Nietzsche’s <em>Case of Wagner</em> and <em>Nietzsche contra Wagner</em>:</p>
<blockquote>
<p>Æsthetic is inextricably bound up with these biological principles: there is decadent æsthetic, and classical æsthetic,—“beauty in itself” is just as much a chimera as any other kind of idealism.—</p>
<p>Æsthetic is indeed <u>nothing more than applied physiology</u>—-</p>
</blockquote>
<p>Wagner makes Nietzsche sick, sick to his stomach.</p>
<blockquote>
<p>[Wagner] stultifies, he befouls the stomach. His specific effect: degeneration of the feeling for rhythm. [referring to leitmotif]</p>
</blockquote>
<p>I think this approach to one’s aesthetics is essentially correct. Revulsion is more powerful than attraction, more immediate and salient. Focusing on it as evidence of your preferences is likely better than waiting for strong feelings of joy or wonder, as it’s more readily available and less fickle.</p>
<p>Which leads to the underlying question: what do I <em>mean</em> when I talk about aesthetics? What <em>is</em> one’s sense of aesthetics? I am gesturing to, I think, a sense of “taste” grounded in feeling, the set of preferences one has. An “aesthete” is just a particularly dense collection of preferences that indicate a feeling towards a certain “vibe”?</p>
<p>In this sense saying “motivate aesthetics with disgust” is misleading — I am actually trying to say something closer to “you will be more successful running a pseudo principal component analysis on your preference set by looking at what you’re disgusted by instead of what you’re attracted to” — and many of these frames have incoherent vocabulary/phenomenon pairings.</p>
<p>When considering one’s aesthetics as one’s preference set, does the cognitive/physiological distinction make any sense? Do different parts of your brain light up when you look at a Van Gogh painting vs. a particularly gory scene in a movie?</p>
<p>Incidentally, beautiful paintings elicit <a href="https://www.science20.com/measuring_mind/your_brain_art">increased activity in your prefrontal cortex</a>, while sadistic tendencies seem to <a href="https://pubmed.ncbi.nlm.nih.gov/22393220/">originate from your amygdala and insula</a>, more primitive areas of the brain. Weak evidence in favor of a mechanistic basis for the cognitive/physiological divide for beauty &amp; disgust.</p>
<p>If I had access to an fMRI machine, I’d get so much data on how our brains react to different kinds of music! (There’s probably already a sufficient amount of literature on this tbf).</p>
<p><em>Ramble, ramble…</em></p>
<p>(i don’t think this is good, i don’t think <a href="/radical-markets">Radical Markets</a> was good (too long), but am experimenting with posting more. potentially bad)</p>
    </section>
</article>
]]></description>
    <pubDate>Sat, 14 Oct 2023 00:00:00 UT</pubDate>
    <guid>https://ykumar.org//aesthetics</guid>
    <dc:creator>Yudhister Kumar</dc:creator>
</item>
<item>
    <title>Radical Markets</title>
    <link>https://ykumar.org//radical-markets</link>
    <description><![CDATA[<article>
    <section class="header">
        Posted on October  6, 2023
        
            by Yudhister Kumar
        
    </section>
    <section>
        <p><img src="/images/radical-markets.jpg" style="float: right; margin: 16px;" width=250 /></p>
<h1 id="rating-25">Rating: 2/5</h1>
<p><em>Radical Markets? More like Activist Markets</em></p>
<p>The <a href="https://www.atlasfellowship.org">Atlas Fellowship</a> partners with <a href="https://www.impactbooks.store">Impact Books</a> to give fellows access to a curated collection of books worth reading. One of these books is <em>Radical Markets</em>. The first two chapters are worth reading, the rest are not.</p>
<p>Posner &amp; Weyl make five proposals to “uproot capitalism and democracy for a just society”:</p>
<ul>
<li>partial common ownership of land, mediated by auctions,</li>
<li>quadratic voting,</li>
<li>individual visa sponsorship,</li>
<li>demonopolizing capital, but only ‘within industries’,</li>
<li>treating data as labor.</li>
</ul>
<p>Each has its own chapter, and each chapter is meant to stand alone as a defense of its policy. Yet the latter three fall flat.</p>
<p>What <em>Radical Markets</em> does well: a coherent exposition of Georgism, ‘radical’ applications of auctions to the uninitiated, and the first decent defense of quadratic voting from first principles I’ve read. What it falls victim to: left-right political reductionism, one-size-fits-all solutions to coordination problems, and hefty claims partnered with weak evidence.</p>
<p>Links to each chapter review:</p>
<ul>
<li><a href="#property-as-monopoly">Property as Monopoly</a></li>
<li><a href="#radical-democracy">Radical Democracy</a></li>
<li><a href="#uniting-the-worlds-workers">Uniting the World’s Workers</a></li>
<li><a href="#dismembering-the-octopus">Dismembering the Octopus</a></li>
<li><a href="#data-as-labor">Data as Labor</a></li>
</ul>
<h1 id="property-as-monopoly">Property as Monopoly</h1>
<p>The first chapter is the best chapter. It popularizes the Common Ownership Self-assessed Tax (COST) (aka the <a href="https://en.wikipedia.org/wiki/Harberger_Tax">Harberger Tax</a>) as a plausible mechanism by which an auction-based property market could be implemented. Coupled with concrete policy proposals and effect analyses, it is a self-contained introduction to modern-day Georgism and disrupting the current ‘property monopoly’ status quo.</p>
<p>What is a COST? In Harberger’s own words:</p>
<blockquote>
<p><em>If taxes are to be levied…on…the value of … properties … it is important that assessment procedures be adopted which estimate the true economic value … The economist’s answer… is simple and essentially fool-proof: allow each…owner.. to declare the value of his own property, make the declared values … public, and require that an owner sell his property to any bidder… willing to pay… the declared value. This system is simple, self-enforcing, allows no scope for corruption, has negligible cost of administration, and creates incentives, in addition to those already present in the market, for each property to be put to that use in which it has the highest economic productivity.</em></p>
<p>- Arnold Harberger, Chile 1962</p>
</blockquote>
<p>Essentially, tax properties based on their value as assessed by the property owner. To ensure that the self-assessed values are accurate representations of the owners’ valuation, make all of the valuations public and mandate that a property be sold if someone outbids the declared value.</p>
<blockquote>
<p>While Harberger designed his scheme as a way to raise government revenue, it offers an inspired solution to the monopoly problem we highlighted above.</p>
</blockquote>
<p>Setting the tax rate requires trading off between allocative and investment efficiency w.r.t. the properties being taxed. If the COST is set at the turnover rate (the probability at which the asset changes hands) then on the margin the property owner’s gains from price increases are exactly offset by tax increases – incentivizing accurate valuations. This maximizes allocative efficiency.</p>
<p>However, such a high tax rate disincentivizes investment. Consider the case of a property owner who by investing $20,000 in his home can raise its value from $40,000 to $70,000. If this home has a turnover rate of 50%, and the COST is set to 50%, this owner will not invest in his home. A $10,000 profit combined with a $15,000 tax increase is not a good financial decision.</p>
<p>Disincentivizing property investment is bad. Private property rights are <em>meant</em> to avert the tragedy of the commons and encourage investment. Any alternative will have to do the same. As such, the socially optimal COST rate is less than the turnover rate.</p>
<p>The socially optimal property COST is non-zero though!</p>
<blockquote>
<p>One might assume that the loss in allocative efficiency would offset the gain in investment efficiency. However – and this is a key point – the opposite happens. When the tax is reduced incrementally to improve investment efficiency, the loss in allocative efficiency is less than the gain in investment efficiency… In fact, it can be shown that the size of the social loss from monopoly power grows quadratically to the extent of this power. Thus, reducing the markup by a third eliminates close to 5/9…of the allocative harm from private ownership.</p>
</blockquote>
<p>One can conceptualize higher COSTs as greater public ownership of private property, as they transfer use value to the public and increase the number of possible owners of the property. In some sense, higher COSTs mean a freer market – more participation, more competition.</p>
<p>How could COSTs be implemented? Countless details would have to be worked out, most in practice, but the salient issues seem to be setting the correct tax rates and developing the necessary infrastructure for frictionless transactions. While the latter is mostly a technological and system design issue (an engineering problem! just an engineering problem), the former is an ideological one. What is the optimal tradeoff?</p>
<blockquote>
<p>For typical assets, we estimate that turnover once every fourteen years is reasonable and thus (combined with other factors below) a 7% tax annually is a good target.</p>
</blockquote>
<p>Posner &amp; Weyl probably get their 7% from the <a href="https://archive.ph/BqOSG">median length of American homeownership</a> being 13.2 years as of 2022. Note that this is essentially setting the COST at the turnover rate, maximizing allocative efficiency at the cost of investment incentivization. They then claim that:</p>
<blockquote>
<p>At the tax rate we advocate, asset prices would fall by between a third and two-thirds from their current level. In popular and congested areas like San Francisco and Boston, where very modest houses sell for $600,000 or more, their price could fall to as low as $200,000.</p>
</blockquote>
<p>Where are these numbers coming from? It seems <em>plausible</em> that prices would fall this much, considering that a 7% COST with a 14 year turnover rate would tax the owner $588,000 and as such they would be incentivized to lower the price of their home to find other buyers faster, leading to lower turnover rates overall and higher profits for owners. Unclear what the underlying model is though.</p>
<p>An important point that they make in footnote 47 of Chapter 1:</p>
<blockquote>
<p>To make our account vivid we discuss some examples of personal possessions of individuals, like homes and cars, but the reader should keep in mind that most assets are owned by businesses and thus much of the participation and benefits from a COST would be through business assets.</p>
</blockquote>
<p>The authors propose starting with implementing COSTs for publicly held assets to enter the private market. For instance, spectrum licenses:</p>
<blockquote>
<p>…redesigning spectrum licenses to include a COST-based license fee would solve [the current misallocation of American spectrum] and could be implemented in a variety of ways consistent with existing FCC rules. This approach, which they call “depreciating licenses,” would address many recent complaints about license design for the newly available 3.5 GHz bands of the spectrum; their small geographic scope and short durations under current plans were intended to maximize flexibility but may undermine investment incentives.</p>
</blockquote>
<p>COSTs on Internet domains, grazing rights, and natural resource leases to name a few also make similar amounts of sense. But, a much broader implementation would reap much greater rewards:</p>
<blockquote>
<p>As we noted above, the economy underperforms by as much as 25% annually because of the misallocation of resources to low productivity firms. A fully implemented COST could increase social wealth by <strong>trillions of dollars</strong> [emphasis mine] every year…</p>
<p>At the rate of roughly 7% annually that we imagine being near-optimal, a COST would raise roughly 20% of national income. About half of that money would suffice to eliminate all existing taxes on capital, corporations, property, and inheritance…and to wipe out the budget deficit and significantly reduce debt, further stimulating investment.</p>
</blockquote>
<p>Where are these numbers coming from?? I don’t doubt that the gains would be large, or that this would be a more efficient taxation regime, but where is the substantiation?? The models are neither in the text of the book nor in the footnotes, and I don’t think it should be on the reader to fact check these claims?</p>
<p>Regardless of this chapter’s issues with providing evidence commensurate to its claims, the underlying proposal of a COST is innovative and, according to John Halstead, perhaps <a href="https://archive.ph/V1FxX">the most serious intellectual challenge to the idea of private property in history</a>. Worth the read.</p>
<h1 id="radical-democracy">Radical Democracy</h1>
<p>In two words: quadratic voting.</p>
<blockquote>
<p>In this chapter, we will show that these two elements – the capacity to save up voting power, and the square root function – would be a much-needed cure to the pathologies of the traditional voting systems used in democracies.</p>
</blockquote>
<p>Why <em>quadratic</em> voting? Why not giving people votes proportional to the cube root of their credits, or the logarithm of their credits? What property does a quadratic have that no other function does?</p>
<p><em>Its derivative is linear.</em> No other function would make the <em>marginal</em> cost of casting an extra vote proportional to the number of votes cast. We make decisions <em>on the margin</em> – if one voter cares three times as much as another voter about an issue, they will be willing to pay three times as much for an extra vote, and as such buy three times as many votes than the other. No other function would lead to the same outcome.</p>
<blockquote>
<p>QV achieves a perfect balance between the free-rider and the tyranny of the majority problems. If the cost of voting increased more steeply, say, as the fourth power of votes cast, those with strong preferences would vote too little and we would revert to a partial tyranny of the majority. If the cost of voting increased more slowly, those with intense preferences would have too much say, as a partial free-rider problem would prevail.</p>
</blockquote>
<p><em>Radical Markets</em> was my first introduction to this explanation, and for this I am grateful. I think this chapter is worth reading just for this, but your mileage may vary.</p>
<p>QV in practice has seen limited adoption. A version is in <a href="https://www.ccn.com/can-ethereum-based-akasha-revolutionize-social-networks/">Akasha</a> (a Ethereum based blockchain application) where money is the currency by which voters buy their votes. Paying for votes has obvious issues in today’s world – perhaps if the world was much more egalitarian, then this would be a better system than one person, one vote.</p>
<p>There is good reason to believe that QV mitigates polarization as a result of allowing individuals to vote more for issues they care more about. Implementation runs into a host of engineering challenges (how to make the UI easy to use &amp; not require excessive amounts of thinking) but I am optimistic that they are solvable.</p>
<p>I doubt this will gain much traction for public elections at the state and national level. It could be useful and innovative for for local and private governance. Notably, the Colorado House Democratic caucus <a href="https://www.bloomberg.com/news/articles/2019-05-01/a-new-way-of-voting-that-makes-zealotry-expensive?leadSource=uverify%20wall">used it in 2019</a> to decide on their legislative priorities, and <a href="https://www.economist.com/open-future/2019/03/12/inside-taiwans-new-digital-democracy">Taiwan has flirted with QV</a> in their digital democracy.</p>
<h1 id="uniting-the-worlds-workers">Uniting the World’s Workers</h1>
<p>Subtitled: <em>REBALANCING THE INTERNATIONAL ORDER TOWARD LABOR</em></p>
<p>The basic argument: economic freedom is necessary for economic growth. Gains from trade have been the primary engine by which this occurs, but as intranational inequality is less severe than international inequality gains from migration should be considered instead. Expanding existing legal migration channels is insufficient and possibly detrimental to natives. Therefore, countries should auction visas and let individuals sponsor migrants. They dub this the Visas between Individuals Program, or VIP.</p>
<p>Bryan Caplan thinks this is his <a href="https://www.econlib.org/radical-markets-in-immigration/">open borders proposal in disguise</a>. I think it’s where the book starts going off the deep end.</p>
<p>I agree with the claim that low-skilled migrants are likely a net drain on the state. As migrants are more likely to work informally and typically send large proportions of their income outside the country, they pay less taxes and consume less than natives. Naturally, this facilitates resentment (amongst a multitude of other cultural reasons, etc.), typically in existing rural, low-income, and more conservative regions.</p>
<p>How is the VIP going to fix this issue, exactly?? Posner and Weyl think that the money generated by the visa auction system will be enough:</p>
<blockquote>
<p>Suppose that OECD countries accepted enough migration to increase their populations by a third. Suppose too that migrants on average bid $6,000 per year for a visa. This sum seems plausible that Mexican migrants to the United States gain more than $11,000 annually under the current highly inefficient system. Average GDP per capita in OECD countries is $35,000, so this proposal would boost the national income of a typical OECD country by almost 6%, comparable to their growth in real income per person in the last five years.</p>
</blockquote>
<p>This is <em>highly</em> optimistic, and assumes that both the demand and quota for visas is at least equivalent to the population of a given OECD country. For America, that’s <em>300 million</em> migrants willing to pay <em>$6,000</em> for a visa <em>per year.</em> This won’t even give you 6% income growth because the GDP per capita in America is so high.</p>
<p>The population of Mexico isn’t even 300 million! The likelihood of most migrants having $6,000 on hand is almost nil! And this money goes to the government, not to private individuals directly – many individuals will not make the connection between increased funding for public services and the <em>massive, massive</em> amounts of migrants this proposal would apparently bring.</p>
<p>Even if migrants would arrive in the numbers that the authors propose, it would utterly, completely, irreversibly change the cultural landscape of the developed world. We are considering migration in numbers such that for every native American there would be a non-native migrant – statistically low-skilled and with poor English. All the typical conservative arguments migration would be multiplied ten-fold, and they would have a point.</p>
<p>But individuals can sponsor visas! Moreso, they can sponsor migrants and get a cut of their earnings such that the migrant earns less than minimum wage! And this isn’t wage slavery because the migrant would be making more than he would have in his home country, so it makes sense!</p>
<blockquote>
<p>The risk of exploitation is minimal because foreign workers are protected by the same health, safety, labor, and employment laws that Americans benefit from, and foreign workers can return to their home country if the employer mistreats them.</p>
</blockquote>
<p>Who <em>enforces</em> these health and safety laws? Americans. What are the economic benefits from arriving from, say, Haiti to the United States? About thirty-fold? What is the likelihood that the system would be abused, ala the Jim Crow South? And even then, what is the likelihood that the migrant would <em>voluntarily return to their home country??</em></p>
<blockquote>
<p>Many people may object to this system. Perhaps to some readers it is uncomfortably similar to indentured servitude, <strong>even though migrants would be free to leave at any time.</strong> Or perhaps it just seems exploitative.</p>
</blockquote>
<p>YES.</p>
<p>Oh, but don’t worry about any of this, because 100 million people will want to sponsor visas.</p>
<blockquote>
<p>Imagine then, that 100 million people sponsor migrant workers. Currently, there are about 45 million foreign-born people in the United States. Of those, about 13 million are legal noncitizens, and 11 million are illegal aliens. If our program replaced existing migrant worker visas [which it wouldn’t], the number of migrant workers would increase dramatically, from 24 million to 100 million, but <strong>not in a way that would disrupt society and overwhelm public services.</strong> [sure] It would leave the ratio of foreign-born to natives in the United States below the numbers in even the most restrictive GCC countries.</p>
</blockquote>
<p>To be clear, 22.7% of Americans would be foreign born, or a little bit less than one in every four American residents would be migrants. Yes, this is a <em>potentially sustainable</em> foreign population, but at once? These GCC countries being used as a reference class are members of the <em>Gulf Cooperation Council.</em> Members include the UAE, Qatar, Kuwait, Bahrain, Oman, and Saudi Arabia. Countries positively praised for their labor rights record.</p>
<p>A more sane reference class would be Australia and New Zealand, which have about one foreigner for every two natives (admittedly, which are mentioned as examples). Where did they come from? According to <a href="https://en.wikipedia.org/wiki/Immigration_to_Australia">Wikipedia</a>:</p>
<blockquote>
<p>After World War II Australia launched a massive immigration program, believing that having narrowly avoided a Japanese invasion, Australia must “populate or perish”. Hundreds of thousands of displaced Europeans migrated to Australia and over 1,000,000 British subjects immigrated under the Assisted Passage Migration Scheme… The scheme initially targeted citizens of all Commonwealth countries; after the war it gradually extended to other countries such as the Netherlands and Italy.</p>
</blockquote>
<p>In other words, Australia heavily enouraged white immigration (see the <a href="https://en.wikipedia.org/wiki/White_Australia_policy">White Australia policy</a>) until the early 1970s, at which point it was comfortable accepting large amounts of migrants. <em>Skilled</em> migrants, I might add. There are only about 1.5 million temporary migrants in Australia (compared to about 7.5 million total foreign-born Australian residents), which is an imperfect yet decent upper bound on the number of low-skilled Australian migrants.</p>
<p>There is no developed country which has managed to have a large foreign-born low-skilled migrant population enter over a short period of time and provide them the same standard of living or the same rights as natives. The GCC has similar proportions of low-skilled workers and an atrocious human rights record; Australia and New Zealand manage to treat migrants decently but with a predominantly high-skilled population.</p>
<p>These are arguments against any open-borders policy that advocates for a large influx of low-skilled immigrants over a short period of time. But the VIP is <em>doubly</em> stupid because it places the liability of migrant well-being on <em>low-skilled natives,</em> the very same people who are the least well equipped to handle it.</p>
<p>Anthony is a native Ohioan, Bishal is a hypothetical migrant under the VIP:</p>
<blockquote>
<p>In our case, Anthony will be required to obtain basic health insurance for Bishal before he arrives (though this would come out of Bishal’s earnings). If Bishal is unable to find work, Anthony must support him for as long as he remains in the country…If Bishal commits a crime, he will be deported after serving his sentence; Anthony will be required to pay a fine. If Bishal disappears, Anthony will also be fined. We do not think that the fine needs to be large, but it should sting.</p>
</blockquote>
<p><em>100 million Americans</em> are supposed to sign up for this??</p>
<p>If you want a defense of open borders &amp; greatly expanded immigration, you can read Caplan’s comic book. Not this.</p>
<h1 id="dismembering-the-octopus">Dismembering the Octopus</h1>
<p>This chapter advocates for letting BlackRock invest in Uber but not Lyft, Coca-Cola but not Pepsi, and McDonald’s but not KFC. Anti-trust for institutional capital. A good idea in theory, but I have doubts about the practical implementation.</p>
<blockquote>
<p>Who are the institutional investors, anyway? They include companies that manage mutual funds and index funds, asset managers, and other firms that buy and hold equities on behalf of their customers. The largest names are those we mentioned above: Vanguard, BlackRock, State Street, and Fidelity.</p>
</blockquote>
<p>26% of the public American stock market is held by institutional investors. As institutional investors are the only single entities with large enough amounts of capital to own significant portions of centibillion dollar companies, they have an outsized influence on industry policy. And because they own significant portions of companies which are nominally supposed to be competing in the same industries, it is in their interest to stifle competition within those industries, creating pseudo-cartels negatively affecting consumers.</p>
<p>As an example, look at banking. BlackRock, Vanguard, State Street, and Fidelity are in the top five largest shareholders of JP Morgan Chase, Bank of America, Citigroup, Wells Fargo, U.S. Bank, <em>and</em> PNC Bank. If the same entities own the companies that are nominally supposed to be competing, the incentives to compete are diminished &amp; monopolistic tendencies being to crop up. Think of Rockefeller after Standard Oil broke up – he still was the owner of the subsidiary companies in each state, and this allowed him to multiply his wealth far beyond what would have been possible if Standard Oil stayed as one company.</p>
<p>Monopolies are bad for consumers! This is what anti-trust law was made to combat! We already bring anti-trust litigation against firm mergers which will increase market concentration, why not do the same for capital investments?</p>
<blockquote>
<p>A simple but Radical reform can prevent this dystopia: ban institutional investors from diversifying their holdings within industries while allowing them to diversity <em>across</em> industries. BlackRock would own as much as it wants of (say) United Airlines, but it would own no stake in Delta, Southwest, and the others. It would also own as much as it wants of Pepsi, but not Coca-Cola and Dr. Pepper. And it would own as much as it wants of JP Morgan, but none of Citigroup and the other banks…</p>
<p>Our approach can be stated as a simple rule:</p>
<p>No investor holding shares of more than a single effective firm in an oligopoly and participating in corporate governance may own more than 1% of the market.</p>
</blockquote>
<p>I agree with this policy, in principle. However, it seems difficult to disambiguate industries cleanly. In today’s world, where a relatively small number of massive corporations control disproportionate amounts of the economy, it seems at least somewhat viable. But what of venture capital firms investing in multiple competing startups? Would they be required to divest from one of them if both become unicorns? How big would an industry have to be for the FTC to care about regulating it?</p>
<p>The authors raise the issue of the lack of usage of anti-trust in local markets. For instance:</p>
<blockquote>
<p>…sociologist Matthew Desmond suggests that landlords in poor neighborhoods often buy up enough housing to have substantial power to drive up rents by holding units vacant and artificially depressing supply. Yet as far as we know, no antitrust case has ever been brought against such local but potentially devastating attempts at monpolization.</p>
</blockquote>
<p>Yes, property is easy to point to as an instance of monopolistic behavior ruining lives. I am wary, however, of giving regulators even more power than they currently have. Property market regulations seem to be, on the whole, good and necessary (or at least, good regulation has the potential to have a large positive impact). But letting regulators control the behaviors of small businesses seems bad? Perhaps giving business owners more leeway to bring civil suits against others engaging in anti-competitive practices is the way to go.</p>
<p>Finally, the authors address the digital economy:</p>
<blockquote>
<p>Antitrust authorities, who are accustomed to worrying about competition within existing, well-defined, and easily measurable markets, have allowed most mergers between dominant tech firms and younger potential disrupters to proceed. Google was allowed to buy mapping startup Waze and artificial intelligence powerhouse DeepMind; Facebook to buy Instagram and WhatsApp; and Microsoft to buy Skype and Linkedin.</p>
</blockquote>
<p>Their solution:</p>
<blockquote>
<p>To prevent this dampening of innovation and competition, antitrust authorities must learn to think more like entrepreneurs and venture capitalists, seeing possibilities beyond existing market structures to the potential markets and technologies of the future, even if these are highly uncertain.</p>
</blockquote>
<p>Much easier said than done. The day a government regulating body has the same market foresight as the entrepreneurs and investors in the market, I will eat my hat.</p>
<p>Meh. Not as groundbreaking as the first two proposals, and not as patently idiotic as the third. It is surprising that they advocate for a drastic expansion in market regulation in a book nominally focused on relying on free market forces to bring about good, but oh well.</p>
<p>(this is where the <em>Activist Markets</em> label came from)</p>
<h1 id="data-as-labor">Data as Labor</h1>
<p><em>Pay people for their data.</em> Never mind that the marginal benefit of your data to any given firm is negligble. Because machine learning systems need large amounts of data and have spiky loss curves, diminishing marginal returns for data doesn’t count here!</p>
<p>(I am not joking, this is the argument Posner &amp; Weyl make)</p>
<blockquote>
<p>However, if later, harder problems are more valuable than earlier, easier ones, then data’s marginal value may increase as more data become available. A classic example of this is speech recognition. Early ML systems for speech recognition achieved gains in accuracy more quickly than did later systems. However, a speech recognition system with all but very high accuracy is mostly useless, as it takes so much time for the user to correct the errors it makes. This means that the last few percentage points of accuracy may make a bigger difference for the value of the system than the first 90% does. The marginal value grows to the extent that it allows this last gap to be filled.</p>
</blockquote>
<p>Maybe the concept of <em>scale, scale, scale</em> wasn’t as prominent in their time as it is nowadays? Two issues: model capabilities grow logarithmically with the amount of data they are trained on, and oftentimes getting from 99% to 99.9% requires as much data as getting from 0% to 99%. The idea that the marginal datapoint has anything but negligible value is absurd.</p>
<p>Paying people for data that’s used to finetune models, sure. Paying people to RLHF models, sure. Paying people for data that’s used in massive datasets – in principle, this should probably happen, but this will come <em>nowhere near</em> to providing individuals with an income equivalent to their job that has just been automated.</p>
<blockquote>
<p>To make a ballpark estimate of what gains we might expect, we suppose that over the next twenty years, AI that would (absent our proposal) not pay data providers comes to represent 10% of the economy. We further assume that the true share of labor if paid in this area of the economy is two-thirds, as in the rest of the economy; and that paying labor fairly expands the output of this sector by 30%, as seems quite reasonable given productivity gains accompanying fairer labor practices in the early twentieth century. Then our proposal would increase the size of the economy by 3% and transfer about 9% of the economy from the owners of capital to those of labor.</p>
</blockquote>
<p>Fundamentally, the authors miss the point that AI will make labor substitutable with non-human entities. The world in five years will likely use datasets generated by AI systems, simply because the Internet is too small for the capabilities of the models we want to build. Paying people for their data is not an alternative to UBI in an increasingly automated economy.</p>
<p>I would critique this chapter more, but it seems like a reasonable proposal to make in the world before ChatGPT and before people realized that scaling laws held to this extent. Still not worth reading in 2023.</p>
    </section>
</article>
]]></description>
    <pubDate>Fri, 06 Oct 2023 00:00:00 UT</pubDate>
    <guid>https://ykumar.org//radical-markets</guid>
    <dc:creator>Yudhister Kumar</dc:creator>
</item>
<item>
    <title>Lord of the Flies</title>
    <link>https://ykumar.org//lord-of-the-flies</link>
    <description><![CDATA[kids and pigs]]></description>
    <pubDate>Tue, 12 Sep 2023 00:00:00 UT</pubDate>
    <guid>https://ykumar.org//lord-of-the-flies</guid>
    <dc:creator>Yudhister Kumar</dc:creator>
</item>
<item>
    <title>Toledo</title>
    <link>https://ykumar.org//toledo</link>
    <description><![CDATA[2AM Amtrak layovers]]></description>
    <pubDate>Mon, 11 Sep 2023 00:00:00 UT</pubDate>
    <guid>https://ykumar.org//toledo</guid>
    <dc:creator>Yudhister Kumar</dc:creator>
</item>
<item>
    <title>Geneva</title>
    <link>https://ykumar.org//geneva</link>
    <description><![CDATA[<article>
    <section class="header">
        Posted on September 11, 2023
        
            by Yudhister Kumar
        
    </section>
    <section>
        <p>Geneva is evil.</p>
<p>It’s overpriced, loud, and dirty. Paying ten francs for a medicore street taco is no way to live life. God forbid you visit the city center during the day, and stay as far away from Geneva station as you can. I thought the air was supposed to be good in the Alps?</p>
<p>But above all, it <em>reeks</em> of <em>fakeness.</em></p>
<p>It calls itself the “Peace Capital”, claims it’s too good to have twin cities, and prides itself on its cosmopolitanism. On what grounds? Before Hitler’s fall, Geneva’s only claim to facilitating international diplomacy was hosting the League of Nations – admittedly the best international governing body we’ve had thus far, but still. After, every international organization and their shadow backers clamored to have their headquarters (or at least their European headquarters) in Geneva. The UN, WHO, UNHCR, Red Cross, WTO, WIPO, WMO, ILO, …</p>
<p>Did you know that the largest non-financial services industry in Geneva is <em>watchmaking?</em> Rolex, Patek Philippe, etc. have factories just outside of Geneva proper. To be fair, ‘financial services’ also excludes commodity trading, of which Geneva is to oil, sugar, grains, and coffee as Rotterdam is to metals. Vitol &amp; Trafigura both have their headquarters in Geneva (and one must wonder whether or not this is for convenience or to take advantage of lax Swiss banking laws…remember Marc Rich?)</p>
<p>Two-thirds of the corporate tax in Geneva comes from commodity trading, banking, and watchmaking. These international organizations? Don’t contribute to the economy. (Yes, they bring people &amp; these people use services &amp; this allows Geneva natives to benefit from the overwhelming amount of NGOs and international bodies in their city. Still.)</p>
<p>Tragically, Geneva once had a soul. The ‘Protestant Rome’ which once served as the birthplace of the Calvinist Revolution was annexed by Catholic France &amp; revolted as a response. The city had <em>opinions</em> that informed its <em>identity</em> – not a pseudo-identity formed from undeserved arrogance &amp; globalism.</p>
<p>Demographic shifts (mostly French immigration to French-speaking Switzerland) led to Catholics forming the largest religious group in Geneva today, followed by atheists. (I am not blaming immigration for Geneva’s soullessness! it is just another piece of the puzzle). This, along with its absurd emphasis on being a truly international city, undergird the sense that <em>Geneve</em> has lost its way.</p>
<p>And the Jet d’Eau… really? Geneva really had to take the self-masturbatory imagery to another level…</p>
    </section>
</article>
]]></description>
    <pubDate>Mon, 11 Sep 2023 00:00:00 UT</pubDate>
    <guid>https://ykumar.org//geneva</guid>
    <dc:creator>Yudhister Kumar</dc:creator>
</item>

    </channel>
</rss>
