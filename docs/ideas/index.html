<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>Random Walks - Ideas</title>
        <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <link rel="stylesheet" href="../css/default.css" />
    </head>
    <body>
        <header>
            <div class="logo">
                <a href="../">Random Walks</a>
            </div>
            <nav>
                <a href="../">Home</a>
                <a href="../about">About</a>
            </nav>
        </header>

        <main role="main">
            <h1>Ideas</h1>
            <article>
    <section class="header">
        Posted on November  3, 2023
        
            by Yudhister Kumar
        
    </section>
    <section>
        <p><em>half-baked ideas. you know the drill.</em></p>
<hr />
<h1 id="feynman-diagrams-gnns">Feynman Diagrams &amp; GNNs</h1>
<p>This one has been on my mind for a while (March 2022).</p>
<p>Fundamentally, Feynman diagrams are just graphs. So, you could probably fit a GNN to a dataset of existing Feynman diagrams and have it learn heuristics to compute them better.</p>
<p><a href="https://arxiv.org/pdf/2211.15348.pdf">Turns out this was done in Nov 2022</a>. Abstract:</p>
<blockquote>
<p>In the wake of the growing popularity of machine learning in particle physics, this
work finds a new application of geometric deep learning on Feynman diagrams to
make accurate and fast matrix element predictions with the potential to be used
in analysis of quantum field theory. This research uses the graph attention layer
which makes matrix element predictions to 1 significant figure accuracy above 90%
of the time. Peak performance was achieved in making predictions to 3 significant
figure accuracy over 10% of the time with less than 200 epochs of training, serving
as a proof of concept on which future works can build upon for better performance.
Finally, a procedure is suggested, to use the network to make advancements in
quantum field theory by constructing Feynman diagrams with effective particles
that represent non-perturbative calculations.</p>
</blockquote>
<p>But there’s more work to do – this is a proof of concept only tested on a limited dataset. I’m excited about integrating this with symbolic regression to recover potentially closed-form heuristics, or applying this to stuff like QCD where Feynman diagram computation is intractable (?)</p>
<p>(although my knowledge of fundamental physics is very lacking)</p>
<h2 id="gnn-stuff">GNN Stuff</h2>
<ul>
<li><a href="https://pytorch-geometric.readthedocs.io/en/latest/">Pytorch Geometric</a></li>
<li><a href="https://github.com/google-deepmind/jraph">Jraph</a> – DeepMind’s JAX based GNN software. Has a really cool <a href="https://github.com/google-deepmind/jraph/blob/master/jraph/examples/higgs_detection.py">Higgs boson detection algorithm</a> as an example. I find this more intuitive than PyG, but also maybe not maintained as well? although it’s been a solid year since I looked at it</li>
<li>I don’t think there’s that much other stuff I’m missing. Maybe good resources for understanding how GNNs work.</li>
</ul>
<h2 id="feynman-diagram-stuff">Feynman Diagram Stuff</h2>
<p>(stuff that might be useful for understanding how to represent Feynman diagrams as graphs idk)</p>
<ul>
<li><a href="https://arxiv.org/pdf/math/0106001.pdf">Feymman Diagrams Via Graphical Calculus</a></li>
<li><a href="https://arxiv.org/pdf/1602.04182.pdf">Feynman Diagrams for Beginners</a></li>
<li>a bunch of other stuff I’m missing</li>
</ul>
<h2 id="symbolic-regression">Symbolic Regression</h2>
<ul>
<li><a href="https://astroautomata.com/PySR/">PySR</a> by Miles Crammer is the only decent symbolic regression software that exists nowdays. The documentation is on his website, not on PyPI. Beware.</li>
<li><a href="https://arxiv.org/pdf/2006.11287.pdf">Discovering Symbolic Models from Deep Learning with Inductive Biases</a> Miles Crammer et. al. use PySR &amp; GNNs to recover &amp; create astrophysics formulae, as well as recovering Newtonian &amp; Hamiltonian dynamics</li>
<li>a bunch of other papers I’m missing</li>
</ul>
<h2 id="bottlenecks">Bottlenecks</h2>
<p>How to represent Feynman diagrams as graphs? Mitchell et. al. have a good formulation which I should still understand better. So, concrete steps:</p>
<ul>
<li>replicate Mitchell et. al. 2022</li>
<li>figure out how it’s limited (likely can’t consider loop diagrams)</li>
<li>CERN is beginning to adopt novel algos for churning through the hundreds of terabytes of data they create each day. They have some really cool stuff on classifying particle jets, and some really cool datasets. Make a better algorithm for that</li>
<li>profit?</li>
</ul>
<h1 id="half-baked">Half-Baked</h1>
<ul>
<li>Longtermism is fake because any practical value model needs to have a time discount factor (for practicality)</li>
<li></li>
</ul>
    </section>
</article>

        </main>

        <footer>
		<a href="../rss.xml">RSS</a><br>
		All thoughts my own.<br>
		Made with
		<a href="http://jaspervdj.be/hakyll">Hakyll</a>.
        </footer>
    </body>
</html>
